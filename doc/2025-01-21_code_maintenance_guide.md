# HÆ°á»›ng Dáº«n Update vÃ  Maintain Code

**NgÃ y táº¡o:** 2025-01-21  
**Má»¥c Ä‘Ã­ch:** HÆ°á»›ng dáº«n chi tiáº¿t cÃ¡ch update, maintain vÃ  má»Ÿ rá»™ng code sau nÃ y

---

## Má»¥c Lá»¥c

1. [Tá»•ng Quan Cáº¥u TrÃºc](#tá»•ng-quan-cáº¥u-trÃºc)
2. [CÃ¡ch Update Paths (ÄÆ°á»ng Dáº«n)](#cÃ¡ch-update-paths-Ä‘Æ°á»ng-dáº«n)
3. [CÃ¡ch Update Config Values](#cÃ¡ch-update-config-values)
4. [CÃ¡ch ThÃªm Utility Functions](#cÃ¡ch-thÃªm-utility-functions)
5. [CÃ¡ch Táº¡o Script Má»›i](#cÃ¡ch-táº¡o-script-má»›i)
6. [Best Practices](#best-practices)
7. [VÃ­ Dá»¥ Cá»¥ Thá»ƒ](#vÃ­-dá»¥-cá»¥-thá»ƒ)
8. [Troubleshooting](#troubleshooting)

---

## Tá»•ng Quan Cáº¥u TrÃºc

### Kiáº¿n TrÃºc Code

```
training/
â”œâ”€â”€ trainer/
â”‚   â”œâ”€â”€ config.py          â† Táº¤T Cáº¢ CONFIG VÃ€ PATHS á» ÄÃ‚Y
â”‚   â”œâ”€â”€ utils.py           â† Táº¤T Cáº¢ UTILITY FUNCTIONS á» ÄÃ‚Y
â”‚   â”œâ”€â”€ preprocessing.py   â† Preprocessing logic
â”‚   â”œâ”€â”€ split_dataset.py   â† Dataset splitting
â”‚   â”œâ”€â”€ build_tokenizer.py â† Tokenizer building
â”‚   â””â”€â”€ clean_noise.py     â† Noise cleaning
â””â”€â”€ ...
```

### NguyÃªn Táº¯c Thiáº¿t Káº¿

1. **Single Source of Truth**: Táº¥t cáº£ config vÃ  paths táº­p trung trong `config.py`
2. **DRY (Don't Repeat Yourself)**: Utilities tÃ¡i sá»­ dá»¥ng trong `utils.py`
3. **Separation of Concerns**: Má»—i module cÃ³ trÃ¡ch nhiá»‡m riÃªng
4. **Easy to Extend**: Dá»… dÃ ng thÃªm config/function má»›i

---

## CÃ¡ch Update Paths (ÄÆ°á»ng Dáº«n)

### Vá»‹ TrÃ­: `training/trainer/config.py`

### Cáº¥u TrÃºc Paths Class

```python
class Paths:
    """Centralized path constants for training pipeline."""
    
    # Project root
    ROOT = Path(__file__).resolve().parents[2]
    
    # Dataset paths
    RAW_DIR = ROOT / "training" / "dataset" / "raw" / "truyenmoiii_output"
    PREPROCESSED_DIR = ROOT / "training" / "dataset" / "preprocessed"
    # ... cÃ¡c paths khÃ¡c
```

### VÃ­ Dá»¥ Update Paths

#### VÃ­ Dá»¥ 1: Äá»•i ThÆ° Má»¥c Raw Data

**TrÆ°á»›c:**
```python
RAW_DIR = ROOT / "training" / "dataset" / "raw" / "truyenmoiii_output"
```

**Sau (náº¿u Ä‘á»•i sang thÆ° má»¥c khÃ¡c):**
```python
RAW_DIR = ROOT / "data" / "raw" / "novels"
```

**Káº¿t quáº£:** Táº¥t cáº£ scripts tá»± Ä‘á»™ng dÃ¹ng path má»›i, khÃ´ng cáº§n sá»­a á»Ÿ chá»— khÃ¡c.

#### VÃ­ Dá»¥ 2: ThÃªm Path Má»›i

**ThÃªm vÃ o Paths class:**
```python
class Paths:
    # ... existing paths ...
    
    # ThÃªm path má»›i
    CACHE_DIR = ROOT / "training" / "cache"
    LOGS_DIR = ROOT / "training" / "logs"
```

**Sá»­ dá»¥ng trong script:**
```python
from .config import Paths

# Tá»± Ä‘á»™ng dÃ¹ng path má»›i
cache_file = Paths.CACHE_DIR / "model_cache.pkl"
```

### LÆ°u Ã

- âœ… **NÃªn:** Sá»­a paths trong `config.py` â†’ Paths class
- âŒ **KhÃ´ng nÃªn:** Hardcode paths trong scripts
- âœ… **NÃªn:** DÃ¹ng `Paths.PATH_NAME` trong táº¥t cáº£ scripts
- âŒ **KhÃ´ng nÃªn:** Táº¡o path constants riÃªng trong má»—i script

---

## CÃ¡ch Update Config Values

### Vá»‹ TrÃ­: `training/trainer/config.py`

### CÃ¡c Config Classes Hiá»‡n CÃ³

1. **PreprocessingConfig**: Config cho preprocessing
2. **TokenizerConfig**: Config cho tokenizer
3. **SplitConfig**: Config cho dataset splitting
4. **CleanNoiseConfig**: Config cho noise cleaning

### VÃ­ Dá»¥ Update Config

#### VÃ­ Dá»¥ 1: Thay Äá»•i Min Paragraph Length

**File:** `training/trainer/config.py`

**TÃ¬m:**
```python
@dataclass
class PreprocessingConfig:
    min_paragraph_length: int = 50  # â† Sá»­a giÃ¡ trá»‹ nÃ y
```

**Sá»­a thÃ nh:**
```python
@dataclass
class PreprocessingConfig:
    min_paragraph_length: int = 100  # Äá»•i tá»« 50 â†’ 100
```

**Káº¿t quáº£:** Preprocessor tá»± Ä‘á»™ng dÃ¹ng giÃ¡ trá»‹ má»›i khi khá»Ÿi táº¡o.

#### VÃ­ Dá»¥ 2: Thay Äá»•i Vocab Size

**TÃ¬m:**
```python
@dataclass
class TokenizerConfig:
    vocab_size: int = 32000  # â† Sá»­a giÃ¡ trá»‹ nÃ y
```

**Sá»­a thÃ nh:**
```python
@dataclass
class TokenizerConfig:
    vocab_size: int = 50000  # Äá»•i tá»« 32000 â†’ 50000
```

#### VÃ­ Dá»¥ 3: Thay Äá»•i Train/Val/Test Ratios

**TÃ¬m:**
```python
@dataclass
class SplitConfig:
    train_ratio: float = 0.9
    val_ratio: float = 0.05
    test_ratio: float = 0.05
```

**Sá»­a thÃ nh:**
```python
@dataclass
class SplitConfig:
    train_ratio: float = 0.8   # Äá»•i tá»« 0.9 â†’ 0.8
    val_ratio: float = 0.1     # Äá»•i tá»« 0.05 â†’ 0.1
    test_ratio: float = 0.1    # Äá»•i tá»« 0.05 â†’ 0.1
```

**LÆ°u Ã½:** Tá»•ng 3 ratios pháº£i = 1.0 (cÃ³ validation tá»± Ä‘á»™ng).

### ThÃªm Config Má»›i

#### BÆ°á»›c 1: Táº¡o Config Class

**ThÃªm vÃ o `config.py`:**
```python
@dataclass
class TrainingConfig:
    """Configuration for model training."""
    
    batch_size: int = 32
    learning_rate: float = 1e-4
    num_epochs: int = 10
    max_seq_length: int = 512
    
    # Paths (optional, defaults to Paths class)
    model_dir: Optional[Path] = None
    
    def __post_init__(self):
        """Set default paths if not provided."""
        if self.model_dir is None:
            self.model_dir = Paths.MODEL_DIR
```

#### BÆ°á»›c 2: Sá»­ Dá»¥ng Config

**Trong script má»›i:**
```python
from .config import TrainingConfig

# Táº¡o config instance
config = TrainingConfig(
    batch_size=64,
    learning_rate=2e-4
)

# Sá»­ dá»¥ng
print(f"Batch size: {config.batch_size}")
print(f"Model dir: {config.model_dir}")
```

### LÆ°u Ã

- âœ… **NÃªn:** Sá»­a config trong `config.py` â†’ Config classes
- âŒ **KhÃ´ng nÃªn:** Hardcode config values trong scripts
- âœ… **NÃªn:** DÃ¹ng dataclass vá»›i type hints
- âœ… **NÃªn:** Validate config values trong `__post_init__`

---

## CÃ¡ch ThÃªm Utility Functions

### Vá»‹ TrÃ­: `training/trainer/utils.py`

### CÃ¡c Utility Functions Hiá»‡n CÃ³

1. `setup_encoding()`: Setup UTF-8 encoding cho Windows
2. `read_jsonl()`: Äá»c JSONL file
3. `write_jsonl()`: Ghi JSONL file
4. `load_json()`: Load JSON file
5. `save_json()`: Save JSON file
6. `ensure_dir()`: Táº¡o directory náº¿u chÆ°a cÃ³

### VÃ­ Dá»¥ ThÃªm Utility Function

#### VÃ­ Dá»¥ 1: ThÃªm Function Äáº¿m Tokens

**ThÃªm vÃ o `utils.py`:**
```python
def count_tokens(text: str, tokenizer) -> int:
    """
    Count tokens in text using tokenizer.
    
    Args:
        text: Input text
        tokenizer: Tokenizer instance
        
    Returns:
        Number of tokens
    """
    return len(tokenizer.encode(text))
```

**Sá»­ dá»¥ng trong script:**
```python
from .utils import count_tokens

# Tá»± Ä‘á»™ng cÃ³ function má»›i
num_tokens = count_tokens("Hello world", tokenizer)
```

#### VÃ­ Dá»¥ 2: ThÃªm Function Format Size

**ThÃªm vÃ o `utils.py`:**
```python
def format_size(size_bytes: int) -> str:
    """
    Format file size in human-readable format.
    
    Args:
        size_bytes: Size in bytes
        
    Returns:
        Formatted string (e.g., "1.5 MB")
    """
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if size_bytes < 1024.0:
            return f"{size_bytes:.2f} {unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.2f} PB"
```

**Sá»­ dá»¥ng:**
```python
from .utils import format_size

file_size = os.path.getsize("data.jsonl")
print(f"File size: {format_size(file_size)}")
```

#### VÃ­ Dá»¥ 3: ThÃªm Function Validate JSONL

**ThÃªm vÃ o `utils.py`:**
```python
def validate_jsonl(path: Path) -> Dict[str, Any]:
    """
    Validate JSONL file and return statistics.
    
    Args:
        path: Path to JSONL file
        
    Returns:
        Dict with validation results
    """
    stats = {
        "total_lines": 0,
        "valid_lines": 0,
        "invalid_lines": 0,
        "errors": []
    }
    
    for line_num, line in enumerate(open(path, 'r', encoding='utf-8'), 1):
        stats["total_lines"] += 1
        if not line.strip():
            continue
        try:
            json.loads(line)
            stats["valid_lines"] += 1
        except json.JSONDecodeError as e:
            stats["invalid_lines"] += 1
            stats["errors"].append({
                "line": line_num,
                "error": str(e)
            })
    
    return stats
```

### LÆ°u Ã

- âœ… **NÃªn:** ThÃªm utilities vÃ o `utils.py` Ä‘á»ƒ tÃ¡i sá»­ dá»¥ng
- âœ… **NÃªn:** Viáº¿t docstring rÃµ rÃ ng vá»›i Args/Returns
- âœ… **NÃªn:** DÃ¹ng type hints
- âŒ **KhÃ´ng nÃªn:** Copy-paste utility code vÃ o nhiá»u scripts
- âœ… **NÃªn:** Handle errors gracefully

---

## CÃ¡ch Táº¡o Script Má»›i

### Template Script Má»›i

```python
"""
Script description here.

This script does X, Y, Z.
"""

import argparse
from pathlib import Path

from .config import Paths, SomeConfig
from .utils import setup_encoding, read_jsonl, write_jsonl


def parse_args():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description="Script description")
    
    parser.add_argument(
        "--input",
        type=Path,
        default=Paths.SOME_INPUT_FILE,
        help="Input file path"
    )
    
    parser.add_argument(
        "--output",
        type=Path,
        default=Paths.SOME_OUTPUT_FILE,
        help="Output file path"
    )
    
    parser.add_argument(
        "--config-value",
        type=int,
        default=100,
        help="Some config value"
    )
    
    return parser.parse_args()


def process_data(input_path: Path, output_path: Path, config_value: int):
    """
    Process data from input to output.
    
    Args:
        input_path: Path to input file
        output_path: Path to output file
        output_path: Some config value
    """
    # Setup encoding
    setup_encoding()
    
    # Read input
    records = read_jsonl(input_path)
    
    # Process
    processed_records = []
    for record in records:
        # Your processing logic here
        processed_record = {
            "text": record["text"],
            "processed": True
        }
        processed_records.append(processed_record)
    
    # Write output
    write_jsonl(output_path, iter(processed_records))
    
    print(f"âœ… Processed {len(processed_records)} records")
    print(f"âœ… Output saved to {output_path}")


def main():
    """Main function."""
    args = parse_args()
    
    # Validate inputs
    if not args.input.exists():
        print(f"âŒ Input file not found: {args.input}")
        return
    
    # Process
    process_data(args.input, args.output, args.config_value)


if __name__ == "__main__":
    main()
```

### BÆ°á»›c Táº¡o Script Má»›i

#### BÆ°á»›c 1: Táº¡o File Má»›i

**Táº¡o file:** `training/trainer/my_new_script.py`

#### BÆ°á»›c 2: Import Config vÃ  Utils

```python
from .config import Paths, SomeConfig
from .utils import setup_encoding, read_jsonl, write_jsonl
```

#### BÆ°á»›c 3: Sá»­ Dá»¥ng Paths

```python
# Thay vÃ¬ hardcode
input_file = Paths.PREPROCESSED_DIR / "data.jsonl"

# Hoáº·c dÃ¹ng config
config = SomeConfig()
output_dir = config.output_dir
```

#### BÆ°á»›c 4: Sá»­ Dá»¥ng Utils

```python
# Setup encoding (quan trá»ng cho Windows)
setup_encoding()

# Read JSONL
for record in read_jsonl(input_path):
    # Process record
    pass

# Write JSONL
write_jsonl(output_path, records)
```

#### BÆ°á»›c 5: ThÃªm Script VÃ o `__init__.py` (Optional)

**File:** `training/trainer/__init__.py`

```python
from .my_new_script import process_data
```

### VÃ­ Dá»¥ Script HoÃ n Chá»‰nh

**File:** `training/trainer/analyze_dataset.py`

```python
"""
Analyze dataset statistics.
"""

import argparse
from pathlib import Path
from collections import Counter

from .config import Paths
from .utils import setup_encoding, read_jsonl, save_json


def analyze_dataset(input_path: Path) -> dict:
    """
    Analyze dataset and return statistics.
    
    Args:
        input_path: Path to input JSONL file
        
    Returns:
        Dict with statistics
    """
    stats = {
        "total_records": 0,
        "total_chars": 0,
        "total_words": 0,
        "novel_counts": Counter()
    }
    
    for record in read_jsonl(input_path):
        stats["total_records"] += 1
        text = record.get("text", "")
        stats["total_chars"] += len(text)
        stats["total_words"] += len(text.split())
        
        novel_id = record.get("novel_id", "unknown")
        stats["novel_counts"][novel_id] += 1
    
    return {
        "total_records": stats["total_records"],
        "total_chars": stats["total_chars"],
        "total_words": stats["total_words"],
        "avg_chars_per_record": stats["total_chars"] / stats["total_records"] if stats["total_records"] > 0 else 0,
        "avg_words_per_record": stats["total_words"] / stats["total_records"] if stats["total_records"] > 0 else 0,
        "num_novels": len(stats["novel_counts"]),
        "novel_counts": dict(stats["novel_counts"])
    }


def main():
    """Main function."""
    parser = argparse.ArgumentParser(description="Analyze dataset")
    parser.add_argument(
        "--input",
        type=Path,
        default=Paths.ALL_NOVELS_PREPROCESSED_CLEAN_JSONL,
        help="Input JSONL file"
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=Paths.PREPROCESSED_DIR / "dataset_stats.json",
        help="Output JSON file"
    )
    
    args = parser.parse_args()
    setup_encoding()
    
    if not args.input.exists():
        print(f"âŒ Input file not found: {args.input}")
        return
    
    print(f"ğŸ“Š Analyzing dataset: {args.input}")
    stats = analyze_dataset(args.input)
    
    save_json(args.output, stats)
    print(f"âœ… Statistics saved to {args.output}")
    print(f"   Total records: {stats['total_records']:,}")
    print(f"   Total chars: {stats['total_chars']:,}")
    print(f"   Total words: {stats['total_words']:,}")


if __name__ == "__main__":
    main()
```

### LÆ°u Ã

- âœ… **NÃªn:** DÃ¹ng config vÃ  utils tá»« Ä‘áº§u
- âœ… **NÃªn:** Viáº¿t docstring cho functions
- âœ… **NÃªn:** Validate inputs
- âœ… **NÃªn:** Handle errors gracefully
- âŒ **KhÃ´ng nÃªn:** Hardcode paths hoáº·c config values
- âŒ **KhÃ´ng nÃªn:** Copy-paste code tá»« scripts khÃ¡c

---

## Best Practices

### 1. Import Order

```python
# Standard library
import argparse
from pathlib import Path

# Local imports
from .config import Paths, SomeConfig
from .utils import setup_encoding, read_jsonl
```

### 2. Error Handling

```python
try:
    data = load_json(path)
except FileNotFoundError:
    print(f"âŒ File not found: {path}")
    return
except json.JSONDecodeError as e:
    print(f"âŒ Invalid JSON: {e}")
    return
```

### 3. Progress Reporting

```python
from .utils import read_jsonl

# Vá»›i progress bar
for record in read_jsonl(input_path, show_progress=True):
    # Process
    pass
```

### 4. Path Validation

```python
from pathlib import Path

def validate_path(path: Path, must_exist: bool = True):
    """Validate path exists."""
    if must_exist and not path.exists():
        raise FileNotFoundError(f"Path not found: {path}")
    return path
```

### 5. Config Usage

```python
# âœ… Good: DÃ¹ng config class
config = PreprocessingConfig(min_paragraph_length=100)
preprocessor = Preprocessor(config)

# âŒ Bad: Hardcode values
preprocessor = Preprocessor(min_paragraph_length=100)
```

---

## VÃ­ Dá»¥ Cá»¥ Thá»ƒ

### Scenario 1: Äá»•i ThÆ° Má»¥c Dataset

**YÃªu cáº§u:** Äá»•i thÆ° má»¥c dataset tá»« `training/dataset` sang `data/dataset`

**BÆ°á»›c 1:** Sá»­a `config.py`

```python
class Paths:
    ROOT = Path(__file__).resolve().parents[2]
    
    # Äá»•i tá»« training/dataset â†’ data/dataset
    RAW_DIR = ROOT / "data" / "dataset" / "raw" / "truyenmoiii_output"
    PREPROCESSED_DIR = ROOT / "data" / "dataset" / "preprocessed"
    SPLITS_DIR = ROOT / "data" / "dataset" / "splits"
    # ... cÃ¡c paths khÃ¡c
```

**Káº¿t quáº£:** Táº¥t cáº£ scripts tá»± Ä‘á»™ng dÃ¹ng paths má»›i.

### Scenario 2: ThÃªm Config Cho Training

**YÃªu cáº§u:** ThÃªm config cho model training

**BÆ°á»›c 1:** ThÃªm config class vÃ o `config.py`

```python
@dataclass
class TrainingConfig:
    """Configuration for model training."""
    
    batch_size: int = 32
    learning_rate: float = 1e-4
    num_epochs: int = 10
    max_seq_length: int = 512
    gradient_accumulation_steps: int = 1
    
    # Paths
    model_dir: Optional[Path] = None
    checkpoint_dir: Optional[Path] = None
    
    def __post_init__(self):
        if self.model_dir is None:
            self.model_dir = Paths.MODEL_DIR
        if self.checkpoint_dir is None:
            self.checkpoint_dir = Paths.MODEL_DIR / "checkpoints"
```

**BÆ°á»›c 2:** Sá»­ dá»¥ng trong training script

```python
from .config import TrainingConfig

config = TrainingConfig(
    batch_size=64,
    learning_rate=2e-4
)

# Training logic sá»­ dá»¥ng config
for epoch in range(config.num_epochs):
    # ...
    pass
```

### Scenario 3: ThÃªm Utility Function

**YÃªu cáº§u:** ThÃªm function tÃ­nh toÃ¡n statistics

**BÆ°á»›c 1:** ThÃªm vÃ o `utils.py`

```python
def compute_statistics(records: Iterator[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Compute statistics from records.
    
    Args:
        records: Iterator of records
        
    Returns:
        Dict with statistics
    """
    stats = {
        "count": 0,
        "total_chars": 0,
        "total_words": 0
    }
    
    for record in records:
        stats["count"] += 1
        text = record.get("text", "")
        stats["total_chars"] += len(text)
        stats["total_words"] += len(text.split())
    
    if stats["count"] > 0:
        stats["avg_chars"] = stats["total_chars"] / stats["count"]
        stats["avg_words"] = stats["total_words"] / stats["count"]
    
    return stats
```

**BÆ°á»›c 2:** Sá»­ dá»¥ng trong scripts

```python
from .utils import read_jsonl, compute_statistics

records = read_jsonl(input_path)
stats = compute_statistics(records)
print(f"Average chars: {stats['avg_chars']:.2f}")
```

---

## Troubleshooting

### Váº¥n Äá» 1: Import Error

**Lá»—i:**
```
ModuleNotFoundError: No module named 'training.trainer'
```

**Giáº£i phÃ¡p:**
- Äáº£m báº£o Ä‘ang cháº¡y tá»« project root
- Kiá»ƒm tra `training/__init__.py` vÃ  `training/trainer/__init__.py` tá»“n táº¡i
- DÃ¹ng relative imports: `from .config import Paths`

### Váº¥n Äá» 2: Path KhÃ´ng ÄÃºng

**Lá»—i:**
```
FileNotFoundError: training/dataset/raw/...
```

**Giáº£i phÃ¡p:**
- Kiá»ƒm tra `Paths.ROOT` Ä‘Ãºng khÃ´ng
- Kiá»ƒm tra paths trong `config.py`
- Äáº£m báº£o directories tá»“n táº¡i hoáº·c dÃ¹ng `ensure_dir()`

### Váº¥n Äá» 3: Config KhÃ´ng Ãp Dá»¥ng

**Lá»—i:** Thay Ä‘á»•i config nhÆ°ng script váº«n dÃ¹ng giÃ¡ trá»‹ cÅ©

**Giáº£i phÃ¡p:**
- Äáº£m báº£o táº¡o config instance má»›i: `config = PreprocessingConfig(...)`
- KhÃ´ng hardcode values trong scripts
- Kiá»ƒm tra default values trong config class

### Váº¥n Äá» 4: Encoding Issues (Windows)

**Lá»—i:** Tiáº¿ng Viá»‡t hiá»ƒn thá»‹ sai

**Giáº£i phÃ¡p:**
- LuÃ´n gá»i `setup_encoding()` á»Ÿ Ä‘áº§u script
- Äáº£m báº£o files Ä‘Æ°á»£c Ä‘á»c/ghi vá»›i `encoding='utf-8'`
- Utils functions Ä‘Ã£ handle encoding tá»± Ä‘á»™ng

---

## TÃ³m Táº¯t

### Checklist Khi Update Code

- [ ] Paths: Sá»­a trong `config.py` â†’ Paths class
- [ ] Config values: Sá»­a trong `config.py` â†’ Config classes
- [ ] Utilities: ThÃªm vÃ o `utils.py`
- [ ] Scripts má»›i: Import tá»« config vÃ  utils
- [ ] KhÃ´ng hardcode paths/config trong scripts
- [ ] Viáº¿t docstring cho functions má»›i
- [ ] Test sau khi update

### Quy Táº¯c VÃ ng

1. **Single Source of Truth**: Config vÃ  paths chá»‰ á»Ÿ `config.py`
2. **DRY**: Utilities chá»‰ á»Ÿ `utils.py`
3. **Easy to Extend**: Dá»… thÃªm config/function má»›i
4. **Maintainable**: Code dá»… Ä‘á»c, dá»… sá»­a

---

## Káº¿t Luáº­n

Vá»›i cáº¥u trÃºc code hiá»‡n táº¡i, viá»‡c update vÃ  maintain code trá»Ÿ nÃªn ráº¥t dá»… dÃ ng:

- âœ… **Update paths**: Chá»‰ sá»­a 1 file (`config.py`)
- âœ… **Update config**: Chá»‰ sá»­a 1 file (`config.py`)
- âœ… **ThÃªm utilities**: Chá»‰ thÃªm vÃ o 1 file (`utils.py`)
- âœ… **Táº¡o script má»›i**: Import sáºµn config vÃ  utils

**LÆ°u Ã½:** LuÃ´n tuÃ¢n thá»§ nguyÃªn táº¯c "Single Source of Truth" - khÃ´ng duplicate config/paths á»Ÿ nhiá»u nÆ¡i.


