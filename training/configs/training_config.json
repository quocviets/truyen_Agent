{
  "model": {
    "vocab_size": 32000,
    "n_ctx": 1024,
    "n_positions": 1024,
    "n_embd": 1024,
    "n_layer": 24,
    "n_head": 16,
    "layer_norm_epsilon": 1e-05,
    "resid_pdrop": 0.1,
    "embd_pdrop": 0.1,
    "attn_pdrop": 0.1
  },
  "training": {
    "num_epochs": 2,
    "learning_rate": 0.0003,
    "weight_decay": 0.1,
    "warmup_steps": 1000,
    "gradient_accumulation_steps": 16,
    "micro_batch_size": 1,
    "max_steps": 0,
    "mixed_precision": "bf16",
    "log_every": 50,
    "eval_every": 500,
    "save_every": 1000,
    "clip_grad_norm": 1.0
  },
  "paths": {
    "train_bin": "training/dataset/tokenized/train_1024.pt",
    "val_bin": "training/dataset/tokenized/val_1024.pt",
    "output_dir": "training/model/350m"
  }
}

